{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('title_abstract.csv', error_bad_lines=False);\n",
    "data_text = data[['text']]\n",
    "data_text['index'] = data_text.index\n",
    "data_text['paper_id'] = data['paperId']\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3982"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>index</th>\n",
       "      <th>paper_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A strategy for managing content complexity in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0000036988a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Efficient passage ranking for document databas...</td>\n",
       "      <td>1</td>\n",
       "      <td>0000764262a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The aditi deductive database system : Deductiv...</td>\n",
       "      <td>2</td>\n",
       "      <td>0000891764a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Housekeeping for prefix coding : We consider t...</td>\n",
       "      <td>3</td>\n",
       "      <td>0001104487a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Memory efficient ranking : Fast and effective ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0001624306a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  index     paper_id\n",
       "0  A strategy for managing content complexity in ...      0  0000036988a\n",
       "1  Efficient passage ranking for document databas...      1  0000764262a\n",
       "2  The aditi deductive database system : Deductiv...      2  0000891764a\n",
       "3  Housekeeping for prefix coding : We consider t...      3  0001104487a\n",
       "4  Memory efficient ranking : Fast and effective ...      4  0001624306a"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatize example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n"
     ]
    }
   ],
   "source": [
    "print(WordNetLemmatizer().lemmatize('went', pos='v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemmer Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original word</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>caresses</td>\n",
       "      <td>caress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flies</td>\n",
       "      <td>fli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dies</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mules</td>\n",
       "      <td>mule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>denied</td>\n",
       "      <td>deni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>died</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>agreed</td>\n",
       "      <td>agre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>owned</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>humbled</td>\n",
       "      <td>humbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sized</td>\n",
       "      <td>size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meeting</td>\n",
       "      <td>meet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stating</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>siezing</td>\n",
       "      <td>siez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>itemization</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sensational</td>\n",
       "      <td>sensat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>traditional</td>\n",
       "      <td>tradit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reference</td>\n",
       "      <td>refer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>colonizer</td>\n",
       "      <td>colon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>plotted</td>\n",
       "      <td>plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original word stemmed\n",
       "0       caresses  caress\n",
       "1          flies     fli\n",
       "2           dies     die\n",
       "3          mules    mule\n",
       "4         denied    deni\n",
       "5           died     die\n",
       "6         agreed    agre\n",
       "7          owned     own\n",
       "8        humbled   humbl\n",
       "9          sized    size\n",
       "10       meeting    meet\n",
       "11       stating   state\n",
       "12       siezing    siez\n",
       "13   itemization    item\n",
       "14   sensational  sensat\n",
       "15   traditional  tradit\n",
       "16     reference   refer\n",
       "17     colonizer   colon\n",
       "18       plotted    plot"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n",
    "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n",
    "           'traditional', 'reference', 'colonizer','plotted']\n",
    "singles = [stemmer.stem(plural) for plural in original_words]\n",
    "pd.DataFrame(data = {'original word': original_words, 'stemmed': singles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "A new class of ternary cocyclic Hadamard codes : We present a new construction for p-ary codes meeting the Plotkin bound, for any odd prime p, from any planar function on the additive group of GF(pa). We use the Coulter-Matthews planar functions with p = 3 to construct new families of ternary cocyclic codes, and compute their dimensions for a ≤ 6.\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['class', 'ternari', 'cocycl', 'hadamard', 'cod', 'present', 'construct', 'cod', 'meet', 'plotkin', 'bind', 'prime', 'planar', 'function', 'addit', 'group', 'coulter', 'matthew', 'planar', 'function', 'construct', 'famili', 'ternari', 'cocycl', 'cod', 'comput', 'dimens']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 150].values[0][0]\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(doc_sample)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = documents['text'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    [effici, consum, respons, survey, australian, ...\n",
       "11    [binari, interpol, cod, effect, index, compres...\n",
       "12    [empir, evalu, cod, method, multi, symbol, alp...\n",
       "13    [fast, algorithm, meld, splay, tree, springer,...\n",
       "14    [effici, object, orient, program, prolog, disc...\n",
       "15    [optim, dynam, multi, attribut, hash, rang, qu...\n",
       "16    [determin, function, languag, introduct, deter...\n",
       "17    [effici, comput, queri, stratifi, databas, mag...\n",
       "18    [share, ground, depend, logic, program, invest...\n",
       "19    [linear, arbor, linear, arbor, regular, graph,...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 accompani\n",
      "1 action\n",
      "2 address\n",
      "3 advantag\n",
      "4 algorithm\n",
      "5 allow\n",
      "6 anim\n",
      "7 avail\n",
      "8 call\n",
      "9 captur\n",
      "10 complex\n",
      "11 content\n",
      "12 control\n",
      "13 coordin\n",
      "14 correspond\n",
      "15 data\n",
      "16 descript\n",
      "17 detail\n",
      "18 differ\n",
      "19 dynam\n",
      "20 educ\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(52, 2), (82, 1), (89, 1), (125, 1), (134, 1), (143, 1), (153, 1), (154, 1), (169, 1), (179, 1), (192, 1), (225, 1), (227, 1), (244, 1), (313, 1), (368, 1), (370, 1), (382, 6), (407, 2), (414, 2), (416, 1), (460, 1), (473, 2), (557, 1), (582, 2), (624, 3), (630, 1), (644, 2), (651, 1), (661, 1), (677, 1), (719, 1), (728, 1), (770, 1), (869, 1), (928, 3), (970, 1), (990, 7), (1311, 4), (1377, 1)]\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "print(bow_corpus[200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running LDA using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel\n",
    "topic_num_coh = []\n",
    "for i in range(10,21):\n",
    "    lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=i, id2word=dictionary, passes=2, workers=2)\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    topic_num_coh.append((i,coherence_lda))\n",
    "topic_num_coh\n",
    "top_num = pd.DataFrame(topic_num_coh)\n",
    "top_num.columns =[\"topic num\", \"Coherence Score\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, '10'),\n",
       " Text(0, 0, '11'),\n",
       " Text(0, 0, '12'),\n",
       " Text(0, 0, '13'),\n",
       " Text(0, 0, '14'),\n",
       " Text(0, 0, '15'),\n",
       " Text(0, 0, '16'),\n",
       " Text(0, 0, '17'),\n",
       " Text(0, 0, '18'),\n",
       " Text(0, 0, '19'),\n",
       " Text(0, 0, '20'),\n",
       " Text(0, 0, '50')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(13,8)})\n",
    "g = sns.barplot(x=\"topic num\", y=\"Coherence Score\", data=top_num)\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.033*\"cloud\" + 0.019*\"data\" + 0.018*\"comput\" + 0.014*\"resourc\" + 0.013*\"applic\" + 0.013*\"servic\" + 0.012*\"base\" + 0.010*\"propos\" + 0.009*\"provid\" + 0.009*\"effici\"\n",
      "Topic: 1 \n",
      "Words: 0.013*\"data\" + 0.011*\"model\" + 0.009*\"algorithm\" + 0.009*\"base\" + 0.008*\"queri\" + 0.008*\"result\" + 0.007*\"pattern\" + 0.007*\"time\" + 0.007*\"method\" + 0.006*\"rank\"\n",
      "Topic: 2 \n",
      "Words: 0.015*\"data\" + 0.014*\"applic\" + 0.013*\"base\" + 0.011*\"comput\" + 0.010*\"resourc\" + 0.010*\"model\" + 0.009*\"algorithm\" + 0.009*\"process\" + 0.009*\"perform\" + 0.009*\"propos\"\n",
      "Topic: 3 \n",
      "Words: 0.013*\"servic\" + 0.011*\"model\" + 0.011*\"base\" + 0.010*\"data\" + 0.009*\"research\" + 0.008*\"system\" + 0.007*\"user\" + 0.007*\"approach\" + 0.007*\"agent\" + 0.006*\"analysi\"\n",
      "Topic: 4 \n",
      "Words: 0.009*\"present\" + 0.009*\"data\" + 0.008*\"approach\" + 0.008*\"algorithm\" + 0.008*\"learn\" + 0.007*\"mobil\" + 0.007*\"applic\" + 0.007*\"inform\" + 0.007*\"method\" + 0.007*\"base\"\n",
      "Topic: 5 \n",
      "Words: 0.014*\"network\" + 0.013*\"time\" + 0.010*\"data\" + 0.010*\"evalu\" + 0.008*\"provid\" + 0.008*\"method\" + 0.007*\"perform\" + 0.007*\"approach\" + 0.007*\"model\" + 0.007*\"base\"\n",
      "Topic: 6 \n",
      "Words: 0.016*\"user\" + 0.012*\"base\" + 0.012*\"method\" + 0.009*\"algorithm\" + 0.009*\"problem\" + 0.008*\"approach\" + 0.008*\"propos\" + 0.007*\"data\" + 0.007*\"trajectori\" + 0.006*\"locat\"\n",
      "Topic: 7 \n",
      "Words: 0.022*\"process\" + 0.014*\"model\" + 0.010*\"technolog\" + 0.009*\"interact\" + 0.009*\"social\" + 0.008*\"network\" + 0.008*\"structur\" + 0.008*\"studi\" + 0.008*\"design\" + 0.007*\"data\"\n",
      "Topic: 8 \n",
      "Words: 0.015*\"algorithm\" + 0.010*\"propos\" + 0.009*\"inform\" + 0.009*\"method\" + 0.008*\"user\" + 0.008*\"process\" + 0.008*\"result\" + 0.007*\"provid\" + 0.007*\"base\" + 0.007*\"resourc\"\n",
      "Topic: 9 \n",
      "Words: 0.017*\"model\" + 0.013*\"data\" + 0.010*\"studi\" + 0.009*\"secur\" + 0.008*\"inform\" + 0.008*\"research\" + 0.007*\"design\" + 0.006*\"base\" + 0.006*\"user\" + 0.006*\"social\"\n",
      "Topic: 10 \n",
      "Words: 0.021*\"data\" + 0.008*\"inform\" + 0.008*\"provid\" + 0.007*\"base\" + 0.007*\"network\" + 0.007*\"perform\" + 0.007*\"method\" + 0.006*\"sequenc\" + 0.006*\"region\" + 0.006*\"optim\"\n",
      "Topic: 11 \n",
      "Words: 0.015*\"comput\" + 0.012*\"grid\" + 0.009*\"resourc\" + 0.009*\"base\" + 0.008*\"applic\" + 0.007*\"manag\" + 0.007*\"method\" + 0.007*\"studi\" + 0.007*\"technolog\" + 0.006*\"workflow\"\n",
      "Topic: 12 \n",
      "Words: 0.020*\"data\" + 0.016*\"model\" + 0.012*\"base\" + 0.011*\"method\" + 0.009*\"user\" + 0.009*\"result\" + 0.008*\"time\" + 0.008*\"process\" + 0.007*\"present\" + 0.007*\"test\"\n",
      "Topic: 13 \n",
      "Words: 0.015*\"approach\" + 0.011*\"base\" + 0.010*\"protocol\" + 0.009*\"data\" + 0.009*\"inform\" + 0.008*\"method\" + 0.007*\"user\" + 0.007*\"agent\" + 0.007*\"propos\" + 0.006*\"result\"\n",
      "Topic: 14 \n",
      "Words: 0.014*\"inform\" + 0.009*\"method\" + 0.009*\"studi\" + 0.008*\"read\" + 0.008*\"evalu\" + 0.008*\"base\" + 0.008*\"model\" + 0.008*\"result\" + 0.007*\"perform\" + 0.007*\"task\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1,10):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Can you distinguish different topics using the words in each topic and their corresponding weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.033*\"cloud\" + 0.019*\"data\" + 0.018*\"comput\" + 0.014*\"resourc\" + 0.013*\"applic\" + 0.013*\"servic\" + 0.012*\"base\" + 0.010*\"propos\" + 0.009*\"provid\" + 0.009*\"effici\"\n",
      "Topic: 1 Word: 0.013*\"data\" + 0.011*\"model\" + 0.009*\"algorithm\" + 0.009*\"base\" + 0.008*\"queri\" + 0.008*\"result\" + 0.007*\"pattern\" + 0.007*\"time\" + 0.007*\"method\" + 0.006*\"rank\"\n",
      "Topic: 2 Word: 0.015*\"data\" + 0.014*\"applic\" + 0.013*\"base\" + 0.011*\"comput\" + 0.010*\"resourc\" + 0.010*\"model\" + 0.009*\"algorithm\" + 0.009*\"process\" + 0.009*\"perform\" + 0.009*\"propos\"\n",
      "Topic: 3 Word: 0.013*\"servic\" + 0.011*\"model\" + 0.011*\"base\" + 0.010*\"data\" + 0.009*\"research\" + 0.008*\"system\" + 0.007*\"user\" + 0.007*\"approach\" + 0.007*\"agent\" + 0.006*\"analysi\"\n",
      "Topic: 4 Word: 0.009*\"present\" + 0.009*\"data\" + 0.008*\"approach\" + 0.008*\"algorithm\" + 0.008*\"learn\" + 0.007*\"mobil\" + 0.007*\"applic\" + 0.007*\"inform\" + 0.007*\"method\" + 0.007*\"base\"\n",
      "Topic: 5 Word: 0.014*\"network\" + 0.013*\"time\" + 0.010*\"data\" + 0.010*\"evalu\" + 0.008*\"provid\" + 0.008*\"method\" + 0.007*\"perform\" + 0.007*\"approach\" + 0.007*\"model\" + 0.007*\"base\"\n",
      "Topic: 6 Word: 0.016*\"user\" + 0.012*\"base\" + 0.012*\"method\" + 0.009*\"algorithm\" + 0.009*\"problem\" + 0.008*\"approach\" + 0.008*\"propos\" + 0.007*\"data\" + 0.007*\"trajectori\" + 0.006*\"locat\"\n",
      "Topic: 7 Word: 0.022*\"process\" + 0.014*\"model\" + 0.010*\"technolog\" + 0.009*\"interact\" + 0.009*\"social\" + 0.008*\"network\" + 0.008*\"structur\" + 0.008*\"studi\" + 0.008*\"design\" + 0.007*\"data\"\n",
      "Topic: 8 Word: 0.015*\"algorithm\" + 0.010*\"propos\" + 0.009*\"inform\" + 0.009*\"method\" + 0.008*\"user\" + 0.008*\"process\" + 0.008*\"result\" + 0.007*\"provid\" + 0.007*\"base\" + 0.007*\"resourc\"\n",
      "Topic: 9 Word: 0.017*\"model\" + 0.013*\"data\" + 0.010*\"studi\" + 0.009*\"secur\" + 0.008*\"inform\" + 0.008*\"research\" + 0.007*\"design\" + 0.006*\"base\" + 0.006*\"user\" + 0.006*\"social\"\n",
      "Topic: 10 Word: 0.021*\"data\" + 0.008*\"inform\" + 0.008*\"provid\" + 0.007*\"base\" + 0.007*\"network\" + 0.007*\"perform\" + 0.007*\"method\" + 0.006*\"sequenc\" + 0.006*\"region\" + 0.006*\"optim\"\n",
      "Topic: 11 Word: 0.015*\"comput\" + 0.012*\"grid\" + 0.009*\"resourc\" + 0.009*\"base\" + 0.008*\"applic\" + 0.007*\"manag\" + 0.007*\"method\" + 0.007*\"studi\" + 0.007*\"technolog\" + 0.006*\"workflow\"\n",
      "Topic: 12 Word: 0.020*\"data\" + 0.016*\"model\" + 0.012*\"base\" + 0.011*\"method\" + 0.009*\"user\" + 0.009*\"result\" + 0.008*\"time\" + 0.008*\"process\" + 0.007*\"present\" + 0.007*\"test\"\n",
      "Topic: 13 Word: 0.015*\"approach\" + 0.011*\"base\" + 0.010*\"protocol\" + 0.009*\"data\" + 0.009*\"inform\" + 0.008*\"method\" + 0.007*\"user\" + 0.007*\"agent\" + 0.007*\"propos\" + 0.006*\"result\"\n",
      "Topic: 14 Word: 0.014*\"inform\" + 0.009*\"method\" + 0.009*\"studi\" + 0.008*\"read\" + 0.008*\"evalu\" + 0.008*\"base\" + 0.008*\"model\" + 0.008*\"result\" + 0.007*\"perform\" + 0.007*\"task\"\n"
     ]
    }
   ],
   "source": [
    "topics = list()\n",
    "for idx, topic in lda_model.print_topics(-1,10):\n",
    "    topics.append({\"topic_id\":idx,\"topic_ref\":topic, \"topic_doc\":[]})\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification of paper and append doc index to each topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(bow_corpus)):\n",
    "    for index, score in sorted(lda_model[bow_corpus[i]], key=lambda tup: -1*tup[1]):\n",
    "        if score > 0.5:\n",
    "            for topic in topics:\n",
    "                if topic[\"topic_id\"] == index:\n",
    "                    topic[\"topic_doc\"].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 [2, 55, 112, 159, 261, 394, 449, 496, 528, 581, 596, 636, 644, 666, 690, 692, 705, 717, 723, 725, 749, 770, 778, 779, 781, 798, 800, 803, 816, 821, 822, 864, 875, 876, 893, 894, 897, 932, 941, 942, 944, 952, 953, 955, 960, 971, 1013, 1027, 1053, 1082, 1083, 1102, 1115, 1133, 1134, 1156, 1165, 1166, 1171, 1190, 1193, 1202, 1206, 1207, 1219, 1230, 1242, 1264, 1265, 1267, 1268, 1277, 1292, 1304, 1318, 1320, 1326, 1329, 1331, 1332, 1348, 1349, 1351, 1370, 1371, 1382, 1388, 1390, 1391, 1401, 1429, 1430, 1441, 1457, 1464, 1466, 1468, 1483, 1490, 1512, 1513, 1528, 1539, 1552, 1609, 1616, 1618, 1619, 1623, 1644, 1648, 1657, 1659, 1666, 1694, 1699, 1704, 1710, 1712, 1713, 1715, 1722, 1765, 1766, 1768, 1781, 1792, 1822, 1836, 1844, 1848, 1866, 1872, 1875, 1876, 1878, 1888, 1889, 1940, 1977, 1982, 1983, 1989, 1996, 1997, 1998, 2006, 2033, 2040, 2041, 2057, 2066, 2067, 2073, 2078, 2110, 2124, 2126, 2132, 2146, 2147, 2148, 2160, 2171, 2173, 2175, 2183, 2208, 2215, 2218, 2225, 2226, 2256, 2277, 2309, 2317, 2342, 2358, 2360, 2370, 2380, 2407, 2427, 2432, 2439, 2454, 2471, 2477, 2484, 2486, 2488, 2511, 2521, 2523, 2524, 2530, 2542, 2545, 2567, 2599, 2604, 2608, 2611, 2613, 2616, 2618, 2619, 2621, 2622, 2625, 2628, 2631, 2656, 2660, 2661, 2671, 2677, 2701, 2739, 2748, 2750, 2759, 2765, 2766, 2767, 2768, 2781, 2783, 2785, 2806, 2820, 2832, 2837, 2838, 2863, 2899, 2921, 2930, 2939, 2948, 2967, 2974, 2981, 2990, 3011, 3022, 3034, 3042, 3076, 3078, 3079, 3080, 3088, 3094, 3099, 3115, 3130, 3132, 3140, 3154, 3157, 3161, 3171, 3175, 3185, 3187, 3191, 3209, 3216, 3222, 3237, 3244, 3271, 3272, 3273, 3280, 3281, 3282, 3290, 3293, 3308, 3336, 3337, 3338, 3341, 3355, 3365, 3369, 3386, 3388, 3390, 3393, 3420, 3424, 3426, 3435, 3443, 3468, 3478, 3486, 3492, 3497, 3512, 3515, 3524, 3525, 3536, 3543, 3546, 3559, 3560, 3565, 3567, 3568, 3575, 3581, 3584, 3589, 3604, 3616, 3619, 3626, 3632, 3638, 3640, 3654, 3655, 3665, 3668, 3683, 3689, 3690, 3695, 3697, 3705, 3711, 3717, 3746, 3748, 3749, 3753, 3761, 3763, 3771, 3772, 3775, 3782, 3792, 3796, 3797, 3808, 3809, 3816, 3828, 3829, 3854, 3890, 3902, 3905, 3934, 3940, 3947]\n",
      "Topic: 1 [1, 4, 9, 13, 17, 19, 29, 44, 57, 60, 61, 65, 76, 82, 113, 132, 154, 161, 162, 173, 177, 179, 188, 198, 236, 262, 273, 278, 279, 281, 282, 289, 304, 316, 317, 322, 324, 372, 373, 379, 381, 382, 397, 402, 403, 407, 409, 425, 430, 437, 440, 445, 455, 475, 479, 486, 501, 506, 514, 527, 560, 561, 569, 594, 601, 609, 625, 630, 637, 662, 664, 665, 671, 683, 714, 732, 738, 741, 750, 761, 763, 790, 813, 817, 827, 829, 835, 845, 849, 858, 882, 884, 887, 889, 891, 892, 912, 933, 958, 990, 998, 1002, 1005, 1025, 1036, 1066, 1073, 1117, 1120, 1129, 1140, 1203, 1223, 1281, 1296, 1300, 1311, 1322, 1327, 1338, 1342, 1357, 1375, 1377, 1381, 1404, 1407, 1433, 1455, 1475, 1481, 1510, 1518, 1523, 1547, 1555, 1561, 1563, 1580, 1593, 1595, 1597, 1621, 1624, 1629, 1658, 1671, 1675, 1742, 1758, 1775, 1808, 1812, 1826, 1827, 1867, 1870, 1871, 1887, 1891, 1916, 1962, 1974, 1985, 2020, 2064, 2071, 2087, 2088, 2136, 2156, 2165, 2187, 2201, 2255, 2270, 2281, 2313, 2347, 2374, 2381, 2412, 2417, 2470, 2474, 2481, 2513, 2520, 2543, 2577, 2594, 2643, 2648, 2664, 2679, 2703, 2705, 2706, 2717, 2719, 2721, 2725, 2754, 2758, 2791, 2808, 2833, 2843, 2874, 2898, 2906, 2909, 2954, 2970, 3053, 3072, 3074, 3121, 3124, 3135, 3188, 3213, 3214, 3269, 3288, 3291, 3397, 3398, 3414, 3511, 3529, 3561, 3574, 3606, 3611, 3612, 3631, 3644, 3647, 3698, 3702, 3745, 3821, 3822, 3838, 3881, 3898, 3920, 3922, 3969, 3978, 3980]\n",
      "Topic: 2 [58, 88, 93, 137, 143, 151, 169, 170, 191, 192, 214, 235, 259, 271, 301, 405, 419, 443, 459, 465, 467, 478, 484, 519, 525, 535, 537, 545, 555, 578, 613, 674, 736, 788, 794, 820, 824, 840, 844, 854, 857, 890, 1004, 1104, 1119, 1121, 1122, 1136, 1173, 1283, 1285, 1307, 1312, 1411, 1471, 1478, 1519, 1530, 1545, 1615, 1647, 1723, 1780, 1795, 1810, 1811, 1813, 1824, 1894, 1975, 1993, 2051, 2099, 2105, 2161, 2190, 2229, 2274, 2297, 2348, 2365, 2414, 2428, 2558, 2597, 2614, 2633, 2635, 2646, 2666, 2676, 2690, 2692, 2720, 2723, 2734, 2746, 2749, 2845, 2860, 2865, 2871, 2880, 2915, 2920, 3001, 3006, 3009, 3010, 3114, 3172, 3173, 3177, 3224, 3225, 3262, 3332, 3345, 3366, 3368, 3395, 3463, 3496, 3519, 3597, 3618, 3625, 3627, 3628, 3652, 3680, 3686, 3691, 3767, 3774, 3776, 3781, 3819, 3825, 3879, 3915, 3939, 3964]\n",
      "Topic: 3 [16, 28, 33, 35, 40, 78, 79, 91, 107, 129, 140, 142, 171, 181, 210, 237, 254, 255, 258, 265, 266, 270, 286, 297, 315, 318, 327, 345, 348, 351, 354, 359, 363, 377, 378, 401, 428, 436, 446, 471, 472, 480, 481, 485, 491, 494, 511, 512, 520, 522, 543, 549, 554, 570, 585, 611, 619, 622, 627, 633, 634, 645, 649, 652, 672, 676, 679, 689, 693, 700, 710, 719, 727, 743, 760, 766, 767, 780, 785, 786, 789, 806, 823, 843, 874, 910, 919, 931, 991, 1003, 1043, 1052, 1063, 1069, 1070, 1093, 1099, 1114, 1144, 1157, 1177, 1191, 1195, 1198, 1229, 1238, 1251, 1270, 1278, 1280, 1290, 1293, 1315, 1378, 1386, 1396, 1423, 1444, 1445, 1492, 1508, 1514, 1531, 1571, 1574, 1582, 1588, 1603, 1613, 1635, 1637, 1638, 1661, 1662, 1668, 1683, 1719, 1729, 1730, 1734, 1743, 1761, 1764, 1790, 1798, 1816, 1831, 1839, 1881, 1890, 1906, 1910, 1936, 1938, 1957, 1970, 1971, 1987, 1990, 1992, 2008, 2009, 2010, 2047, 2053, 2061, 2085, 2090, 2103, 2114, 2123, 2131, 2143, 2184, 2186, 2239, 2242, 2251, 2278, 2289, 2292, 2299, 2310, 2311, 2321, 2332, 2354, 2364, 2368, 2386, 2394, 2403, 2422, 2430, 2445, 2451, 2453, 2482, 2483, 2525, 2639, 2640, 2685, 2691, 2694, 2695, 2709, 2712, 2737, 2743, 2757, 2773, 2780, 2782, 2786, 2797, 2802, 2814, 2840, 2850, 2878, 2892, 2901, 2903, 2919, 2933, 2973, 2976, 2978, 3002, 3014, 3015, 3030, 3049, 3054, 3059, 3064, 3093, 3125, 3156, 3167, 3176, 3193, 3203, 3215, 3231, 3264, 3267, 3279, 3304, 3314, 3316, 3317, 3321, 3357, 3373, 3379, 3404, 3412, 3431, 3442, 3445, 3446, 3502, 3507, 3508, 3514, 3547, 3552, 3555, 3558, 3576, 3605, 3617, 3621, 3649, 3661, 3663, 3664, 3688, 3724, 3727, 3730, 3759, 3779, 3780, 3791, 3798, 3801, 3803, 3817, 3826, 3830, 3852, 3901, 3925, 3930, 3944, 3954, 3956, 3958, 3962, 3977]\n",
      "Topic: 4 [45, 144, 164, 193, 200, 287, 303, 332, 368, 400, 442, 453, 458, 466, 483, 495, 515, 588, 631, 648, 668, 731, 733, 793, 851, 904, 945, 954, 979, 985, 1012, 1019, 1035, 1037, 1085, 1124, 1135, 1141, 1182, 1222, 1226, 1271, 1325, 1362, 1418, 1421, 1437, 1452, 1529, 1543, 1551, 1604, 1686, 1739, 1778, 1968, 2019, 2028, 2035, 2042, 2054, 2055, 2072, 2077, 2079, 2081, 2109, 2113, 2120, 2166, 2206, 2247, 2296, 2335, 2359, 2362, 2392, 2413, 2464, 2465, 2466, 2506, 2517, 2537, 2541, 2564, 2566, 2570, 2586, 2595, 2642, 2647, 2662, 2696, 2698, 2704, 2756, 2761, 2798, 2830, 2836, 2847, 2853, 2858, 2867, 2872, 2891, 2904, 2944, 2953, 2969, 2988, 3144, 3163, 3164, 3178, 3241, 3257, 3343, 3346, 3375, 3416, 3453, 3500, 3523, 3534, 3537, 3550, 3579, 3610, 3622, 3629, 3630, 3634, 3636, 3643, 3662, 3671, 3692, 3758, 3805, 3806, 3812, 3832, 3837, 3884, 3923, 3945, 3953, 3973]\n",
      "Topic: 5 [6, 14, 22, 23, 24, 25, 27, 53, 66, 73, 114, 134, 156, 199, 203, 219, 292, 294, 299, 334, 342, 364, 367, 406, 499, 526, 540, 544, 548, 557, 566, 574, 592, 615, 680, 688, 708, 740, 748, 768, 773, 774, 784, 810, 842, 850, 860, 861, 862, 867, 896, 914, 1000, 1018, 1050, 1077, 1092, 1097, 1101, 1106, 1131, 1174, 1215, 1248, 1255, 1287, 1294, 1302, 1308, 1313, 1317, 1345, 1364, 1384, 1392, 1395, 1413, 1424, 1493, 1525, 1550, 1556, 1565, 1567, 1584, 1589, 1611, 1645, 1667, 1702, 1740, 1757, 1762, 1783, 1787, 1833, 1852, 1914, 1919, 1976, 1991, 2003, 2023, 2052, 2076, 2093, 2202, 2211, 2249, 2283, 2322, 2349, 2363, 2366, 2385, 2415, 2440, 2442, 2475, 2478, 2487, 2494, 2532, 2538, 2550, 2552, 2562, 2598, 2615, 2627, 2805, 2818, 2834, 2839, 2855, 2873, 2893, 2929, 2962, 2975, 2980, 2982, 2995, 3016, 3027, 3048, 3061, 3081, 3101, 3147, 3210, 3219, 3232, 3251, 3265, 3283, 3284, 3287, 3294, 3303, 3305, 3320, 3347, 3348, 3399, 3557, 3562, 3591, 3637, 3726, 3756, 3790, 3839, 3874, 3878, 3880, 3889, 3949, 3974]\n",
      "Topic: 6 [85, 96, 153, 202, 208, 340, 399, 435, 552, 565, 583, 595, 909, 964, 987, 1075, 1095, 1149, 1210, 1232, 1250, 1253, 1254, 1336, 1379, 1387, 1393, 1458, 1484, 1559, 1586, 1612, 1628, 1685, 1703, 1706, 1711, 1817, 1840, 2069, 2106, 2134, 2139, 2144, 2162, 2192, 2209, 2224, 2248, 2285, 2290, 2469, 2491, 2507, 2531, 2534, 2539, 2582, 2600, 2829, 2854, 2876, 2877, 2905, 2938, 2941, 2994, 3023, 3060, 3065, 3066, 3077, 3087, 3104, 3189, 3217, 3266, 3311, 3350, 3352, 3360, 3403, 3418, 3422, 3475, 3483, 3499, 3522, 3535, 3539, 3554, 3620, 3660, 3667, 3673, 3682, 3684, 3716, 3783, 3849, 3859, 3871, 3873, 3897, 3971, 3976]\n",
      "Topic: 7 [10, 37, 68, 75, 102, 111, 117, 131, 209, 260, 300, 309, 310, 312, 331, 333, 347, 360, 362, 396, 413, 503, 562, 610, 612, 614, 616, 617, 620, 623, 624, 626, 647, 650, 657, 675, 704, 728, 729, 752, 759, 762, 764, 765, 802, 833, 839, 865, 885, 918, 924, 929, 930, 938, 939, 967, 976, 988, 1006, 1016, 1017, 1045, 1048, 1054, 1055, 1057, 1058, 1059, 1060, 1061, 1081, 1086, 1105, 1126, 1138, 1139, 1151, 1159, 1169, 1176, 1178, 1181, 1189, 1196, 1197, 1227, 1246, 1252, 1273, 1275, 1333, 1339, 1343, 1347, 1360, 1366, 1398, 1403, 1410, 1412, 1420, 1449, 1450, 1451, 1462, 1474, 1476, 1477, 1485, 1505, 1506, 1517, 1521, 1522, 1535, 1540, 1570, 1572, 1573, 1577, 1600, 1626, 1641, 1642, 1656, 1665, 1670, 1677, 1705, 1716, 1721, 1725, 1732, 1736, 1738, 1741, 1745, 1747, 1749, 1750, 1751, 1752, 1753, 1754, 1756, 1763, 1772, 1774, 1796, 1809, 1819, 1821, 1828, 1829, 1841, 1846, 1851, 1853, 1857, 1860, 1861, 1864, 1893, 1899, 1909, 1923, 1926, 1927, 1929, 1947, 1948, 1954, 1955, 1956, 1986, 2000, 2004, 2005, 2011, 2012, 2018, 2038, 2045, 2046, 2059, 2062, 2080, 2083, 2091, 2094, 2098, 2100, 2101, 2111, 2149, 2216, 2243, 2259, 2291, 2293, 2295, 2300, 2307, 2308, 2323, 2324, 2327, 2329, 2333, 2334, 2336, 2337, 2338, 2340, 2341, 2343, 2346, 2351, 2352, 2357, 2379, 2389, 2390, 2402, 2426, 2443, 2448, 2472, 2497, 2499, 2501, 2503, 2504, 2527, 2551, 2553, 2556, 2557, 2560, 2563, 2565, 2569, 2571, 2573, 2579, 2581, 2584, 2585, 2587, 2601, 2609, 2617, 2629, 2636, 2657, 2665, 2672, 2673, 2682, 2686, 2687, 2697, 2711, 2713, 2714, 2715, 2730, 2738, 2807, 2809, 2810, 2815, 2823, 2827, 2868, 2869, 2882, 2883, 2890, 2912, 2913, 2928, 2945, 2952, 2956, 2961, 2991, 2996, 2997, 2998, 3017, 3018, 3031, 3032, 3041, 3043, 3047, 3055, 3057, 3073, 3082, 3083, 3084, 3098, 3103, 3109, 3110, 3112, 3116, 3119, 3126, 3131, 3133, 3143, 3145, 3151, 3183, 3186, 3190, 3202, 3226, 3230, 3243, 3248, 3254, 3277, 3278, 3312, 3318, 3319, 3325, 3362, 3370, 3372, 3374, 3382, 3396, 3400, 3405, 3407, 3423, 3430, 3436, 3440, 3441, 3449, 3452, 3457, 3466, 3469, 3480, 3482, 3488, 3495, 3506, 3513, 3517, 3520, 3538, 3577, 3578, 3582, 3586, 3592, 3598, 3614, 3639, 3650, 3669, 3672, 3701, 3710, 3719, 3723, 3728, 3731, 3733, 3734, 3742, 3744, 3766, 3768, 3815, 3833, 3845, 3847, 3851, 3857, 3861, 3867, 3887, 3895, 3896, 3924, 3927, 3938, 3952, 3955, 3966, 3975]\n",
      "Topic: 8 [0, 3, 5, 8, 11, 12, 15, 20, 21, 26, 31, 34, 36, 39, 41, 46, 47, 48, 51, 54, 59, 63, 67, 70, 81, 83, 87, 90, 97, 98, 100, 104, 121, 123, 126, 130, 152, 155, 158, 168, 175, 183, 194, 207, 211, 223, 225, 228, 231, 248, 249, 250, 251, 263, 268, 276, 280, 290, 305, 339, 341, 349, 353, 357, 361, 366, 370, 371, 374, 380, 383, 404, 408, 415, 429, 434, 450, 451, 454, 463, 469, 487, 497, 498, 529, 533, 556, 571, 593, 605, 641, 646, 667, 696, 697, 706, 711, 715, 716, 726, 742, 754, 787, 804, 815, 832, 837, 841, 859, 871, 873, 879, 880, 898, 915, 925, 928, 966, 968, 974, 983, 1009, 1040, 1046, 1088, 1128, 1147, 1155, 1204, 1208, 1243, 1244, 1258, 1310, 1341, 1355, 1426, 1427, 1431, 1432, 1453, 1501, 1527, 1569, 1581, 1587, 1590, 1598, 1599, 1606, 1684, 1700, 1737, 1769, 1782, 1789, 1849, 1901, 1911, 1913, 1918, 1920, 1966, 1994, 2001, 2034, 2056, 2082, 2102, 2112, 2115, 2116, 2122, 2128, 2151, 2153, 2157, 2158, 2174, 2189, 2221, 2228, 2258, 2261, 2268, 2273, 2284, 2312, 2325, 2345, 2396, 2421, 2423, 2437, 2444, 2461, 2495, 2510, 2514, 2548, 2554, 2568, 2572, 2574, 2589, 2591, 2607, 2658, 2675, 2722, 2724, 2729, 2732, 2736, 2787, 2792, 2793, 2794, 2795, 2803, 2824, 2831, 2835, 2914, 2947, 3019, 3037, 3039, 3040, 3062, 3095, 3108, 3168, 3195, 3199, 3200, 3212, 3218, 3240, 3242, 3299, 3306, 3377, 3383, 3402, 3450, 3473, 3476, 3477, 3487, 3491, 3509, 3541, 3544, 3583, 3633, 3648, 3653, 3715, 3720, 3754, 3795, 3813, 3900, 3910, 3911, 3916, 3933, 3936, 3941, 3950]\n",
      "Topic: 9 [18, 72, 101, 115, 116, 166, 230, 234, 242, 243, 293, 295, 319, 320, 321, 328, 329, 330, 335, 343, 344, 352, 356, 385, 387, 391, 411, 418, 420, 421, 423, 426, 431, 444, 448, 477, 488, 500, 509, 517, 524, 536, 567, 575, 577, 579, 580, 607, 670, 673, 681, 685, 686, 702, 734, 735, 756, 758, 771, 776, 777, 795, 814, 834, 872, 888, 900, 901, 913, 922, 926, 934, 935, 936, 937, 946, 950, 970, 977, 980, 986, 994, 995, 997, 1001, 1010, 1028, 1041, 1049, 1051, 1068, 1072, 1080, 1094, 1096, 1108, 1127, 1142, 1143, 1145, 1163, 1164, 1183, 1201, 1231, 1266, 1269, 1298, 1305, 1350, 1354, 1359, 1365, 1373, 1376, 1399, 1406, 1436, 1438, 1472, 1486, 1489, 1491, 1495, 1509, 1533, 1554, 1557, 1576, 1579, 1608, 1610, 1625, 1627, 1631, 1640, 1655, 1664, 1673, 1707, 1717, 1718, 1727, 1770, 1773, 1785, 1791, 1820, 1835, 1843, 1847, 1855, 1858, 1869, 1877, 1882, 1886, 1895, 1903, 1917, 1925, 1930, 1931, 1932, 1945, 1946, 1950, 1951, 1959, 1965, 1978, 1979, 1981, 2029, 2039, 2048, 2096, 2104, 2107, 2108, 2118, 2125, 2137, 2145, 2150, 2152, 2167, 2168, 2177, 2182, 2196, 2198, 2213, 2223, 2252, 2254, 2262, 2267, 2280, 2286, 2301, 2306, 2316, 2320, 2330, 2331, 2339, 2344, 2387, 2409, 2410, 2411, 2425, 2429, 2431, 2455, 2456, 2480, 2492, 2493, 2508, 2512, 2519, 2528, 2544, 2547, 2561, 2575, 2576, 2578, 2580, 2583, 2588, 2645, 2650, 2652, 2667, 2669, 2670, 2684, 2689, 2700, 2710, 2731, 2735, 2747, 2772, 2775, 2816, 2819, 2826, 2848, 2870, 2881, 2927, 2937, 2958, 2972, 2977, 2987, 2989, 2993, 3007, 3029, 3058, 3068, 3071, 3085, 3086, 3090, 3091, 3092, 3105, 3122, 3142, 3146, 3149, 3162, 3165, 3166, 3198, 3211, 3223, 3253, 3255, 3256, 3274, 3275, 3285, 3286, 3289, 3322, 3323, 3324, 3342, 3356, 3364, 3367, 3385, 3387, 3406, 3408, 3410, 3425, 3429, 3432, 3433, 3451, 3454, 3459, 3462, 3494, 3526, 3532, 3571, 3573, 3587, 3590, 3595, 3596, 3603, 3615, 3635, 3641, 3675, 3696, 3703, 3707, 3725, 3729, 3735, 3741, 3752, 3760, 3765, 3786, 3802, 3810, 3827, 3843, 3844, 3846, 3855, 3862, 3865, 3877, 3882, 3888, 3904, 3907, 3908, 3912, 3913, 3914, 3917, 3921, 3946, 3959]\n",
      "Topic: 10 [30, 38, 42, 43, 56, 71, 77, 84, 99, 108, 110, 139, 150, 165, 189, 204, 205, 212, 264, 272, 285, 350, 375, 376, 388, 389, 416, 460, 505, 523, 530, 586, 587, 599, 663, 730, 745, 747, 791, 796, 895, 957, 959, 975, 981, 1008, 1023, 1024, 1032, 1033, 1039, 1064, 1113, 1172, 1180, 1184, 1200, 1234, 1261, 1274, 1279, 1282, 1335, 1352, 1358, 1409, 1414, 1417, 1439, 1443, 1479, 1488, 1497, 1498, 1524, 1548, 1553, 1558, 1568, 1583, 1585, 1605, 1633, 1674, 1678, 1695, 1720, 1802, 1805, 1807, 1825, 1854, 1873, 1902, 1907, 1969, 2002, 2016, 2044, 2121, 2142, 2197, 2203, 2214, 2244, 2245, 2253, 2266, 2272, 2279, 2282, 2298, 2315, 2361, 2367, 2398, 2436, 2462, 2489, 2533, 2590, 2593, 2605, 2610, 2644, 2742, 2751, 2762, 2769, 2800, 2856, 2931, 2959, 2963, 2966, 2983, 3026, 3028, 3050, 3067, 3129, 3184, 3194, 3236, 3249, 3307, 3315, 3328, 3349, 3361, 3380, 3392, 3472, 3474, 3484, 3490, 3580, 3642, 3646, 3651, 3657, 3757, 3800, 3818, 3866, 3968]\n",
      "Topic: 11 [86, 103, 149, 196, 215, 227, 291, 338, 422, 461, 473, 518, 539, 542, 550, 564, 590, 597, 655, 660, 712, 744, 757, 769, 782, 825, 869, 870, 916, 947, 996, 1047, 1062, 1103, 1110, 1158, 1245, 1247, 1262, 1435, 1459, 1463, 1537, 1620, 1714, 1731, 1746, 1771, 1779, 1784, 1794, 1803, 1856, 1912, 1924, 1937, 1953, 1960, 2022, 2063, 2065, 2169, 2185, 2200, 2235, 2275, 2326, 2375, 2395, 2435, 2447, 2450, 2452, 2458, 2630, 2634, 2651, 2678, 2740, 2752, 2760, 2776, 2828, 2864, 2894, 2917, 2918, 2925, 2934, 2949, 2964, 3024, 3120, 3139, 3169, 3204, 3221, 3415, 3439, 3540, 3585, 3593, 3608, 3623, 3693, 3789, 3807, 3823, 3835, 3894, 3937]\n",
      "Topic: 12 [32, 62, 89, 109, 118, 120, 122, 124, 125, 127, 135, 136, 138, 146, 147, 160, 176, 178, 185, 186, 195, 220, 221, 226, 232, 277, 288, 302, 313, 314, 346, 369, 386, 392, 395, 462, 468, 489, 490, 493, 504, 510, 531, 551, 568, 573, 621, 628, 638, 639, 651, 653, 707, 709, 720, 818, 838, 846, 853, 856, 866, 908, 917, 927, 956, 965, 982, 984, 989, 1011, 1015, 1031, 1042, 1076, 1116, 1118, 1146, 1150, 1160, 1170, 1185, 1186, 1187, 1188, 1199, 1216, 1224, 1249, 1260, 1276, 1289, 1295, 1299, 1303, 1314, 1316, 1319, 1324, 1328, 1344, 1374, 1428, 1447, 1448, 1467, 1470, 1487, 1499, 1520, 1536, 1538, 1562, 1602, 1614, 1617, 1650, 1651, 1693, 1726, 1733, 1759, 1767, 1788, 1793, 1797, 1818, 1904, 1939, 1942, 1963, 1967, 1988, 2015, 2024, 2025, 2026, 2037, 2138, 2140, 2155, 2176, 2219, 2220, 2246, 2294, 2371, 2382, 2420, 2434, 2441, 2460, 2509, 2516, 2526, 2596, 2602, 2641, 2654, 2702, 2755, 2770, 2777, 2799, 2821, 2822, 2825, 2846, 2861, 2889, 2895, 2900, 2902, 2922, 2940, 2946, 2957, 3020, 3025, 3033, 3038, 3106, 3111, 3118, 3150, 3158, 3170, 3207, 3227, 3276, 3300, 3313, 3330, 3333, 3351, 3363, 3384, 3411, 3421, 3444, 3471, 3481, 3528, 3531, 3545, 3548, 3549, 3551, 3553, 3556, 3588, 3600, 3658, 3694, 3714, 3743, 3751, 3769, 3777, 3824, 3842, 3876, 3891, 3903, 3918, 3928, 3943, 3951, 3960, 3961]\n",
      "Topic: 13 [95, 105, 106, 233, 245, 246, 256, 390, 414, 417, 432, 433, 470, 474, 476, 482, 492, 502, 513, 532, 538, 547, 602, 658, 659, 677, 678, 687, 701, 739, 755, 783, 805, 807, 812, 899, 911, 951, 993, 1014, 1020, 1026, 1029, 1074, 1087, 1090, 1098, 1109, 1130, 1152, 1175, 1221, 1236, 1321, 1380, 1408, 1454, 1456, 1469, 1507, 1516, 1566, 1653, 1669, 1676, 1697, 1724, 1863, 1941, 1943, 2049, 2070, 2095, 2129, 2130, 2179, 2199, 2232, 2302, 2304, 2319, 2328, 2353, 2376, 2399, 2419, 2612, 2626, 2681, 2733, 2744, 2851, 2884, 2887, 2936, 2943, 2950, 3000, 3117, 3179, 3205, 3297, 3310, 3331, 3335, 3354, 3358, 3409, 3427, 3434, 3447, 3455, 3465, 3521, 3533, 3602, 3613, 3677, 3709, 3721, 3885, 3957]\n",
      "Topic: 14 [184, 213, 216, 239, 247, 252, 253, 257, 296, 306, 311, 325, 326, 337, 355, 447, 534, 563, 589, 600, 632, 635, 643, 654, 656, 694, 699, 713, 721, 722, 737, 746, 809, 830, 847, 852, 883, 886, 905, 920, 949, 962, 999, 1007, 1021, 1044, 1071, 1079, 1084, 1111, 1154, 1179, 1194, 1220, 1233, 1235, 1239, 1240, 1241, 1257, 1291, 1330, 1346, 1353, 1361, 1363, 1367, 1368, 1369, 1389, 1405, 1416, 1419, 1422, 1425, 1465, 1482, 1494, 1526, 1541, 1564, 1578, 1592, 1594, 1596, 1632, 1634, 1649, 1679, 1680, 1687, 1688, 1691, 1735, 1800, 1837, 1896, 1898, 1908, 1935, 1999, 2014, 2021, 2032, 2036, 2043, 2050, 2058, 2086, 2089, 2133, 2163, 2170, 2172, 2188, 2217, 2287, 2350, 2378, 2393, 2397, 2405, 2408, 2416, 2418, 2424, 2459, 2476, 2479, 2500, 2502, 2505, 2522, 2559, 2655, 2659, 2668, 2680, 2716, 2764, 2788, 2789, 2790, 2813, 2817, 2841, 2842, 2849, 2879, 2888, 2923, 2951, 2986, 3044, 3045, 3070, 3075, 3096, 3123, 3127, 3128, 3137, 3152, 3153, 3155, 3181, 3246, 3292, 3295, 3309, 3327, 3334, 3353, 3456, 3479, 3518, 3679, 3685, 3712, 3740, 3747, 3750, 3794, 3804, 3929, 3935, 3948, 3979]\n"
     ]
    }
   ],
   "source": [
    "for topic in topics:\n",
    "    print(\"Topic:\",topic[\"topic_id\"], topic[\"topic_doc\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Topic info to Couch DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopic(i):    \n",
    "    print(docText(documents,i))\n",
    "    for index, score in sorted(lda_model_tfidf[bow_corpus[i]], key=lambda tup: -1*tup[1]):\n",
    "        topic_ref = lda_model_tfidf.print_topic(index);\n",
    "        print(score,topic_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def docText(documents,index):\n",
    "    text = documents[documents['index'] == index].values[0][0]\n",
    "    return text\n",
    "\n",
    "def getTopicId(i):    \n",
    "#     print(docText(documents,i))\n",
    "    topic_ids = list()\n",
    "    for index, score in sorted(lda_model[bow_corpus[i]], key=lambda tup: -1*tup[1]):\n",
    "        topic_ref = lda_model.print_topic(index);\n",
    "        for topic in topics:\n",
    "            if topic_ref == topic[\"topic_ref\"]:\n",
    "                topic_ids.append(topic[\"topic_id\"])\n",
    "    return topic_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['sensor', 'mutation', 'protein', 'sensor network', 'word sense', 'data', 'mining'], 1: ['clustering', 'interaction', 'community', 'exertion', 'gesture', 'process model', 'graph', 'measure'], 2: ['health', 'security', 'social', 'digital election', 'information', 'e-voting', 'internet technology', 'data privacy'], 3: ['cloud', 'public display', 'agent', 'game play', 'data center', 'energy consumption'], 4: ['query', 'document', 'location', 'data compression', 'search', 'model', 'tree', 'poi'], 5: ['complementary pair', 'arithmetic', 'correlation', 'optimal'], 6: ['code', 'security', 'clustering', 'coding', 'trajectory', 'privacy', 'attack', 'dependency', 'minimum redundancy', 'redundancy'], 7: ['game agent', 'mobile', 'technology', 'interaction', 'display', 'social', 'workshop', 'device', 'feedback', 'gesture'], 8: ['process', 'process model', 'graph', 'health', 'model', 'older', 'adoption', 'child', 'adult', 'older adult', 'clustering', 'protein', 'display', 'event', 'measure'], 9: ['agent', 'meta', 'xcp', 'max min', 'max', 'min', 'equilibrium', 'template', 'behaviour', 'pedestrian', 'fairness', 'meta model', 'groundness', 'fuzzy', 'fuzzy rule'], 10: ['resource', 'grid', 'cloud cluster', 'service', 'scheduling', 'optical', 'packet', 'energy', 'optical network', 'network', 'agent', 'allocation', 'core', 'size'], 11: ['word', 'string', 'scheme', 'deep', 'event', 'file', 'lexicon', 'query', 'forum', 'database', 'binary', 'index', 'retrieval', 'constraint', 'statement'], 12: ['document', 'compression', 'metric', 'query', 'word relevance', 'text retrieval', 'judgment', 'human', 'visual', 'collection', 'contrast'], 13: ['event', 'model', 'cloud', 'graph', 'behavioral', 'event log', 'program', 'resource', 'path', 'relation check'], 14: ['feedback', 'surgical', 'gene', 'feature', 'bone', 'selection', 'feature selection', 'classifier', 'xc', 'training', 'temporal bone', 'simulator']}\n"
     ]
    }
   ],
   "source": [
    "topic_keyword = {}\n",
    "topic_keyword[0] = ['sensor','mutation','protein', 'sensor network', 'word sense','data', 'mining']\n",
    "topic_keyword[1] = ['clustering', 'interaction', 'community', 'exertion', 'gesture','process model','graph', 'measure']\n",
    "topic_keyword[2] = ['health','security', 'social', 'digital election', 'information', 'e-voting', 'internet technology', 'data privacy']\n",
    "topic_keyword[3] = ['cloud','public display','agent','game play','data center','energy consumption']\n",
    "topic_keyword[4] = ['query', 'document','location','data compression','search','model','tree','poi']\n",
    "topic_keyword[5] = ['complementary pair','arithmetic','correlation','optimal']\n",
    "topic_keyword[6] = ['code','security','clustering','coding','trajectory','privacy','attack','dependency','minimum redundancy','redundancy']\n",
    "topic_keyword[7] = ['game agent', 'mobile','technology', 'interaction', 'display', 'social', 'workshop', 'device','feedback', 'gesture']\n",
    "topic_keyword[8] = ['process', 'process model', 'graph', 'health', 'model', 'older', 'adoption', 'child', 'adult', 'older adult', 'clustering', 'protein', 'display', 'event', 'measure']\n",
    "topic_keyword[9] = ['agent', 'meta', 'xcp', 'max min', 'max', 'min', 'equilibrium', 'template', 'behaviour', 'pedestrian', 'fairness', 'meta model', 'groundness', 'fuzzy', 'fuzzy rule']\n",
    "topic_keyword[10] = ['resource', 'grid', 'cloud cluster', 'service', 'scheduling', 'optical', 'packet', 'energy', 'optical network', 'network', 'agent', 'allocation', 'core', 'size']\n",
    "topic_keyword[11] = ['word', 'string', 'scheme', 'deep', 'event', 'file', 'lexicon', 'query', 'forum', 'database', 'binary', 'index', 'retrieval', 'constraint', 'statement']\n",
    "topic_keyword[12] = ['document', 'compression', 'metric', 'query', 'word relevance', 'text retrieval', 'judgment', 'human', 'visual', 'collection', 'contrast']\n",
    "topic_keyword[13] = ['event', 'model', 'cloud', 'graph', 'behavioral', 'event log', 'program', 'resource', 'path', 'relation check']\n",
    "topic_keyword[14] = ['feedback', 'surgical', 'gene', 'feature', 'bone', 'selection', 'feature selection', 'classifier', 'xc', 'training', 'temporal bone', 'simulator']\n",
    "\n",
    "print(topic_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPaperID(index):\n",
    "    id = documents[documents['index'] == index].values[0][2]\n",
    "    return id[:-1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopicInfo(index):\n",
    "#     for index, score in sorted(lda_model_tfidf[bow_corpus[index]], key=lambda tup: -1*tup[1]):\n",
    "#         print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index)))\n",
    "    topic_ids = getTopicId(index)\n",
    "    if(len(topic_ids)>3):\n",
    "        topic_ids = topic_ids[0:2]\n",
    "    return topic_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import couchdb\n",
    "import csv\n",
    "\n",
    "couch=couchdb.Server(\"http://admin:password@localhost:5984\")\n",
    "try:\n",
    "    database=couch[\"paperinfo_scopus\"]\n",
    "except:\n",
    "    print(\"wrong db name\")\n",
    "    \n",
    "def addTopic(index):\n",
    "    id = getPaperID(index)\n",
    "    doc = database.get(id)\n",
    "#     todo : adding topic info:\n",
    "    doc[\"topic_ids\"] = getTopicInfo(index)\n",
    "    doc = database.save(doc)\n",
    "    \n",
    "for i in range(0,len(documents)):\n",
    "    addTopic(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    topic_database=couch[\"paper_topic\"]\n",
    "except:\n",
    "    print(\"wrong db name\")\n",
    "    \n",
    "def saveTopicKeyword(i):\n",
    "    doc = {}\n",
    "    doc['_id'] = str(i)\n",
    "    doc['topic_keywords'] = topic_keyword[i]\n",
    "    doc = topic_database.save(doc)\n",
    "\n",
    "for i in topic_keyword:\n",
    "    saveTopicKeyword(i)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(15, 1), (42, 2), (48, 2), (67, 1), (84, 1), (96, 1), (103, 1), (143, 1), (160, 1), (193, 1), (199, 1), (204, 2), (262, 3), (312, 1), (317, 1), (348, 2), (349, 1), (414, 1), (435, 4), (436, 1), (456, 1), (483, 1), (545, 1), (678, 1), (864, 2), (918, 1), (939, 1), (940, 1), (968, 1), (970, 2), (1081, 1), (1210, 1), (1211, 1), (1212, 1), (1213, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(bow_corpus[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model on unseen document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.3733212351799011\t Topic: 0.006*\"mobile\" + 0.005*\"data\" + 0.004*\"social\" + 0.004*\"privacy\" + 0.003*\"research\"\n",
      "Score: 0.26307183504104614\t Topic: 0.006*\"cloud\" + 0.005*\"process\" + 0.005*\"data\" + 0.004*\"model\" + 0.004*\"document\"\n",
      "Score: 0.16387544572353363\t Topic: 0.006*\"game\" + 0.005*\"data\" + 0.004*\"design\" + 0.003*\"network\" + 0.003*\"mutations\"\n",
      "Score: 0.11993960291147232\t Topic: 0.005*\"cluster\" + 0.004*\"model\" + 0.004*\"data\" + 0.004*\"program\" + 0.003*\"network\"\n",
      "Score: 0.06462649255990982\t Topic: 0.004*\"data\" + 0.003*\"model\" + 0.003*\"network\" + 0.003*\"query\" + 0.003*\"process\"\n"
     ]
    }
   ],
   "source": [
    "# unseen_document = \"machine learning\"\n",
    "unseen_document = \"The use of randomness in the designing of the digital devices has been discussed. Qualities of randomness such as unpredictability, indeterminacy and unexpectedness have been used as a creative resource to generate innovative , output. Randomness is a creative tool to inspire and generate innovative outputs that is a means to an end. The growth of digital interactivity has been accompanied by a increasing amount of interactive that express certain qualities of randomness during use. An emergent approach toward randomness is to allow users to interact directly with the randomness. Shuffle listening, which is an alternative listening mode offered by digital music players, is a more sophisticated approach, whereby application of randomness has publicly captured by imagination of many people. Considerations, in determining where a random feature can be used, should include the types of content, the domain and contexts where these digital devices are used\"\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "\n",
    "print(\"document:\")\n",
    "print(unseen_document)\n",
    "print(\"Relete Topic:\")\n",
    "for index, score in sorted(lda_model_tfidf[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model_tfidf.print_topic(index, 5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
