{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('title_abstract.csv', error_bad_lines=False);\n",
    "data_text = data[['text']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3982"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A strategy for managing content complexity in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Efficient passage ranking for document databas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The aditi deductive database system:Deductive ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Housekeeping for prefix coding:We consider the...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Memory efficient ranking:Fast and effective ra...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  index\n",
       "0  A strategy for managing content complexity in ...      0\n",
       "1  Efficient passage ranking for document databas...      1\n",
       "2  The aditi deductive database system:Deductive ...      2\n",
       "3  Housekeeping for prefix coding:We consider the...      3\n",
       "4  Memory efficient ranking:Fast and effective ra...      4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatize example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n"
     ]
    }
   ],
   "source": [
    "print(WordNetLemmatizer().lemmatize('went', pos='v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemmer Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original word</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>caresses</td>\n",
       "      <td>caress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flies</td>\n",
       "      <td>fli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dies</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mules</td>\n",
       "      <td>mule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>denied</td>\n",
       "      <td>deni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>died</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>agreed</td>\n",
       "      <td>agre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>owned</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>humbled</td>\n",
       "      <td>humbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sized</td>\n",
       "      <td>size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meeting</td>\n",
       "      <td>meet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stating</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>siezing</td>\n",
       "      <td>siez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>itemization</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sensational</td>\n",
       "      <td>sensat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>traditional</td>\n",
       "      <td>tradit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reference</td>\n",
       "      <td>refer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>colonizer</td>\n",
       "      <td>colon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>plotted</td>\n",
       "      <td>plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original word stemmed\n",
       "0       caresses  caress\n",
       "1          flies     fli\n",
       "2           dies     die\n",
       "3          mules    mule\n",
       "4         denied    deni\n",
       "5           died     die\n",
       "6         agreed    agre\n",
       "7          owned     own\n",
       "8        humbled   humbl\n",
       "9          sized    size\n",
       "10       meeting    meet\n",
       "11       stating   state\n",
       "12       siezing    siez\n",
       "13   itemization    item\n",
       "14   sensational  sensat\n",
       "15   traditional  tradit\n",
       "16     reference   refer\n",
       "17     colonizer   colon\n",
       "18       plotted    plot"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n",
    "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n",
    "           'traditional', 'reference', 'colonizer','plotted']\n",
    "singles = [stemmer.stem(plural) for plural in original_words]\n",
    "pd.DataFrame(data = {'original word': original_words, 'stemmed': singles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['Using', 'emerging', 'patterns', 'and', 'decision', 'trees', 'in', 'rare-class', 'classification:The', 'problem', 'of', 'classifying', 'rarely', 'occurring', 'cases', 'is', 'faced', 'in', 'many', 'real', 'life', 'applications.', 'The', 'scarcity', 'of', 'the', 'rare', 'cases', 'makes', 'it', 'difficult', 'to', 'classify', 'them', 'correctly', 'using', 'traditional', 'classifiers.', 'In', 'this', 'paper,', 'we', 'propose', 'a', 'new', 'approach', 'to', 'use', 'emerging', 'patterns', '(EPs)', 'and', 'decision', 'trees', '(DTs)', 'in', 'rare-class', 'classification', '(EPDT).', 'EPs', 'are', 'those', 'itemsets', 'whose', 'supports', 'in', 'one', 'class', 'are', 'significantly', 'higher', 'than', 'their', 'supports', 'in', 'the', 'other', 'classes.', 'EPDT', 'employs', 'the', 'power', 'of', 'EPs', 'to', 'improve', 'the', 'quality', 'of', 'rare-case', 'classification.', 'To', 'achieve', 'this', 'aim,', 'we', 'first', 'introduce', 'the', 'idea', 'of', 'generating', 'new', 'non-existing', 'rare-class', 'instances,', 'and', 'then', 'we', 'over-sample', 'the', 'most', 'important', 'rare-class', 'instances.', 'Our', 'experiments', 'show', 'that', 'EPDT', 'outperforms', 'many', 'classification', 'methods.', '©', '2004', 'IEEE.']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['emerge', 'pattern', 'decision', 'tree', 'rare', 'class', 'classification', 'problem', 'classify', 'rarely', 'occur', 'case', 'face', 'real', 'life', 'applications', 'scarcity', 'rare', 'case', 'make', 'difficult', 'classify', 'correctly', 'traditional', 'classifiers', 'paper', 'propose', 'approach', 'emerge', 'pattern', 'decision', 'tree', 'rare', 'class', 'classification', 'epdt', 'itemsets', 'support', 'class', 'significantly', 'higher', 'support', 'class', 'epdt', 'employ', 'power', 'improve', 'quality', 'rare', 'case', 'classification', 'achieve', 'introduce', 'idea', 'generate', 'exist', 'rare', 'class', 'instance', 'sample', 'important', 'rare', 'class', 'instance', 'experiment', 'epdt', 'outperform', 'classification', 'methods', 'ieee']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 200].values[0][0]\n",
    "\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = documents['text'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    [efficient, consumer, response, survey, austra...\n",
       "11    [binary, interpolative, cod, effective, index,...\n",
       "12    [empirical, evaluation, cod, methods, multi, s...\n",
       "13    [fast, algorithm, meld, splay, tree, springer,...\n",
       "14    [efficient, object, orient, program, prolog, d...\n",
       "15    [optimal, dynamic, multi, attribute, hash, ran...\n",
       "16    [determinism, functional, languages, introduct...\n",
       "17    [efficient, computation, query, stratify, data...\n",
       "18    [share, groundness, dependencies, logic, progr...\n",
       "19    [linear, arboricity, linear, arboricity, regul...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 accompany\n",
      "1 action\n",
      "2 address\n",
      "3 advantage\n",
      "4 algorithm\n",
      "5 algorithms\n",
      "6 allow\n",
      "7 animation\n",
      "8 availability\n",
      "9 call\n",
      "10 capture\n",
      "11 complexity\n",
      "12 content\n",
      "13 control\n",
      "14 coordinate\n",
      "15 correspond\n",
      "16 correspondingly\n",
      "17 data\n",
      "18 description\n",
      "19 detail\n",
      "20 different\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (3, 1),\n",
       " (4, 3),\n",
       " (5, 2),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 1),\n",
       " (9, 1),\n",
       " (10, 3),\n",
       " (11, 2),\n",
       " (12, 2),\n",
       " (13, 1),\n",
       " (14, 1),\n",
       " (15, 2),\n",
       " (16, 1),\n",
       " (17, 1),\n",
       " (18, 1),\n",
       " (19, 1),\n",
       " (20, 1),\n",
       " (21, 1),\n",
       " (22, 1),\n",
       " (23, 2),\n",
       " (24, 2),\n",
       " (25, 1),\n",
       " (26, 1),\n",
       " (27, 1),\n",
       " (28, 1),\n",
       " (29, 2),\n",
       " (30, 2),\n",
       " (31, 1),\n",
       " (32, 5),\n",
       " (33, 1),\n",
       " (34, 3),\n",
       " (35, 1),\n",
       " (36, 1),\n",
       " (37, 1),\n",
       " (38, 1),\n",
       " (39, 1),\n",
       " (40, 1),\n",
       " (41, 1),\n",
       " (42, 1),\n",
       " (43, 1),\n",
       " (44, 1),\n",
       " (45, 1),\n",
       " (46, 1),\n",
       " (47, 1),\n",
       " (48, 2),\n",
       " (49, 2),\n",
       " (50, 2),\n",
       " (51, 1),\n",
       " (52, 1),\n",
       " (53, 2),\n",
       " (54, 1),\n",
       " (55, 2),\n",
       " (56, 1),\n",
       " (57, 1),\n",
       " (58, 2)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 52 (\"support\") appears 2 time.\n",
      "Word 82 (\"improv\") appears 1 time.\n",
      "Word 89 (\"method\") appears 1 time.\n",
      "Word 125 (\"power\") appears 1 time.\n",
      "Word 134 (\"applic\") appears 1 time.\n",
      "Word 143 (\"ieee\") appears 1 time.\n",
      "Word 153 (\"problem\") appears 1 time.\n",
      "Word 154 (\"propos\") appears 1 time.\n",
      "Word 169 (\"experi\") appears 1 time.\n",
      "Word 179 (\"make\") appears 1 time.\n",
      "Word 192 (\"achiev\") appears 1 time.\n",
      "Word 225 (\"generat\") appears 1 time.\n",
      "Word 227 (\"idea\") appears 1 time.\n",
      "Word 244 (\"signific\") appears 1 time.\n",
      "Word 313 (\"difficult\") appears 1 time.\n",
      "Word 368 (\"import\") appears 1 time.\n",
      "Word 370 (\"introduc\") appears 1 time.\n",
      "Word 382 (\"class\") appears 6 time.\n",
      "Word 407 (\"emerg\") appears 2 time.\n",
      "Word 414 (\"tree\") appears 2 time.\n",
      "Word 416 (\"correct\") appears 1 time.\n",
      "Word 460 (\"approach\") appears 1 time.\n",
      "Word 473 (\"decis\") appears 2 time.\n",
      "Word 557 (\"occur\") appears 1 time.\n",
      "Word 582 (\"pattern\") appears 2 time.\n",
      "Word 624 (\"case\") appears 3 time.\n",
      "Word 630 (\"qualiti\") appears 1 time.\n",
      "Word 644 (\"instanc\") appears 2 time.\n",
      "Word 651 (\"employ\") appears 1 time.\n",
      "Word 661 (\"outperform\") appears 1 time.\n",
      "Word 677 (\"sampl\") appears 1 time.\n",
      "Word 719 (\"tradit\") appears 1 time.\n",
      "Word 728 (\"real\") appears 1 time.\n",
      "Word 770 (\"exist\") appears 1 time.\n",
      "Word 869 (\"higher\") appears 1 time.\n",
      "Word 928 (\"classifi\") appears 3 time.\n",
      "Word 970 (\"face\") appears 1 time.\n",
      "Word 990 (\"rare\") appears 7 time.\n",
      "Word 1311 (\"classif\") appears 4 time.\n",
      "Word 1377 (\"life\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_200 = bow_corpus[200]\n",
    "\n",
    "for i in range(len(bow_doc_200)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_200[i][0], \n",
    "                                                     dictionary[bow_doc_200[i][0]], \n",
    "                                                     bow_doc_200[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.13902024201089283),\n",
      " (1, 0.08738507861257963),\n",
      " (2, 0.05560774368588772),\n",
      " (3, 0.0791816638102688),\n",
      " (4, 0.14352583658639353),\n",
      " (5, 0.10910353492379238),\n",
      " (6, 0.05162349826212706),\n",
      " (7, 0.0936195163175166),\n",
      " (8, 0.06745830242255361),\n",
      " (9, 0.07298609187290764),\n",
      " (10, 0.2379756189349876),\n",
      " (11, 0.16574354387081996),\n",
      " (12, 0.12768481932381914),\n",
      " (13, 0.10646707892303645),\n",
      " (14, 0.09491313051487732),\n",
      " (15, 0.05240028255162777),\n",
      " (16, 0.11365800280661265),\n",
      " (17, 0.0879846057230066),\n",
      " (18, 0.041019228725238055),\n",
      " (19, 0.06588179592755974),\n",
      " (20, 0.12541250036660845),\n",
      " (21, 0.06026441641299527),\n",
      " (22, 0.13131851031809763),\n",
      " (23, 0.22622010416689314),\n",
      " (24, 0.27512783682281844),\n",
      " (25, 0.117218959126369),\n",
      " (26, 0.1281947592721971),\n",
      " (27, 0.12723318377348622),\n",
      " (28, 0.08965594094958554),\n",
      " (29, 0.1071803839263706),\n",
      " (30, 0.11865616974829668),\n",
      " (31, 0.05823551306319199),\n",
      " (32, 0.2763476276719661),\n",
      " (33, 0.0791816638102688),\n",
      " (34, 0.24861531580622995),\n",
      " (35, 0.11597584787241458),\n",
      " (36, 0.0681915537923395),\n",
      " (37, 0.10910516357441133),\n",
      " (38, 0.13902024201089283),\n",
      " (39, 0.0595258508860087),\n",
      " (40, 0.07232139174232721),\n",
      " (41, 0.13902024201089283),\n",
      " (42, 0.03797562473066158),\n",
      " (43, 0.03189002829747558),\n",
      " (44, 0.14220923951141592),\n",
      " (45, 0.11658982280098115),\n",
      " (46, 0.10524386515280033),\n",
      " (47, 0.0812688077780112),\n",
      " (48, 0.11271265018380498),\n",
      " (49, 0.2384106398545789),\n",
      " (50, 0.1966306807218592),\n",
      " (51, 0.06962600723888682),\n",
      " (52, 0.04274052438488875),\n",
      " (53, 0.2384106398545789),\n",
      " (54, 0.12723318377348622),\n",
      " (55, 0.12066526517847484),\n",
      " (56, 0.04771674268910695),\n",
      " (57, 0.08371273033941232),\n",
      " (58, 0.15893912417871536)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running LDA using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=20, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.015*\"data\" + 0.012*\"cloud\" + 0.011*\"security\" + 0.009*\"service\" + 0.008*\"base\" + 0.007*\"model\" + 0.007*\"time\" + 0.007*\"propose\" + 0.007*\"compute\" + 0.006*\"approach\"\n",
      "Topic: 1 \n",
      "Words: 0.015*\"data\" + 0.008*\"design\" + 0.008*\"model\" + 0.008*\"social\" + 0.007*\"study\" + 0.007*\"research\" + 0.007*\"network\" + 0.006*\"public\" + 0.006*\"provide\" + 0.006*\"information\"\n",
      "Topic: 2 \n",
      "Words: 0.019*\"model\" + 0.015*\"base\" + 0.013*\"approach\" + 0.012*\"process\" + 0.011*\"data\" + 0.008*\"user\" + 0.007*\"propose\" + 0.007*\"users\" + 0.007*\"information\" + 0.007*\"structure\"\n",
      "Topic: 3 \n",
      "Words: 0.012*\"network\" + 0.010*\"design\" + 0.008*\"base\" + 0.008*\"model\" + 0.007*\"result\" + 0.007*\"data\" + 0.007*\"propose\" + 0.007*\"cloud\" + 0.007*\"systems\" + 0.006*\"information\"\n",
      "Topic: 4 \n",
      "Words: 0.019*\"model\" + 0.011*\"process\" + 0.010*\"base\" + 0.009*\"data\" + 0.008*\"analysis\" + 0.008*\"information\" + 0.008*\"result\" + 0.007*\"study\" + 0.007*\"approach\" + 0.006*\"present\"\n",
      "Topic: 5 \n",
      "Words: 0.013*\"model\" + 0.009*\"result\" + 0.008*\"cod\" + 0.007*\"information\" + 0.007*\"base\" + 0.007*\"user\" + 0.007*\"users\" + 0.006*\"provide\" + 0.006*\"data\" + 0.006*\"work\"\n",
      "Topic: 6 \n",
      "Words: 0.031*\"cloud\" + 0.018*\"service\" + 0.013*\"compute\" + 0.008*\"resources\" + 0.008*\"base\" + 0.007*\"result\" + 0.007*\"applications\" + 0.007*\"time\" + 0.007*\"research\" + 0.007*\"provide\"\n",
      "Topic: 7 \n",
      "Words: 0.014*\"data\" + 0.014*\"algorithm\" + 0.008*\"price\" + 0.008*\"information\" + 0.007*\"performance\" + 0.007*\"accuracy\" + 0.006*\"base\" + 0.006*\"method\" + 0.006*\"propose\" + 0.006*\"change\"\n",
      "Topic: 8 \n",
      "Words: 0.018*\"data\" + 0.009*\"base\" + 0.008*\"read\" + 0.008*\"cod\" + 0.008*\"service\" + 0.008*\"cloud\" + 0.007*\"present\" + 0.007*\"users\" + 0.007*\"model\" + 0.006*\"time\"\n",
      "Topic: 9 \n",
      "Words: 0.037*\"data\" + 0.014*\"process\" + 0.013*\"cloud\" + 0.010*\"pattern\" + 0.010*\"model\" + 0.008*\"approach\" + 0.008*\"result\" + 0.007*\"base\" + 0.007*\"service\" + 0.006*\"compute\"\n",
      "Topic: 10 \n",
      "Words: 0.020*\"document\" + 0.010*\"test\" + 0.009*\"measure\" + 0.008*\"base\" + 0.007*\"similarity\" + 0.007*\"data\" + 0.007*\"cluster\" + 0.007*\"result\" + 0.007*\"information\" + 0.006*\"algorithm\"\n",
      "Topic: 11 \n",
      "Words: 0.011*\"base\" + 0.011*\"data\" + 0.009*\"study\" + 0.009*\"systems\" + 0.007*\"file\" + 0.006*\"test\" + 0.006*\"sense\" + 0.006*\"present\" + 0.006*\"propose\" + 0.006*\"method\"\n",
      "Topic: 12 \n",
      "Words: 0.011*\"process\" + 0.009*\"technology\" + 0.009*\"level\" + 0.008*\"model\" + 0.008*\"study\" + 0.008*\"information\" + 0.007*\"research\" + 0.007*\"systems\" + 0.007*\"provide\" + 0.007*\"data\"\n",
      "Topic: 13 \n",
      "Words: 0.016*\"process\" + 0.015*\"model\" + 0.010*\"approach\" + 0.009*\"task\" + 0.007*\"propose\" + 0.006*\"topic\" + 0.006*\"result\" + 0.006*\"base\" + 0.006*\"study\" + 0.006*\"test\"\n",
      "Topic: 14 \n",
      "Words: 0.016*\"time\" + 0.013*\"data\" + 0.013*\"sequence\" + 0.009*\"base\" + 0.008*\"propose\" + 0.008*\"process\" + 0.007*\"cluster\" + 0.007*\"approach\" + 0.007*\"algorithm\" + 0.007*\"method\"\n",
      "Topic: 15 \n",
      "Words: 0.013*\"model\" + 0.011*\"process\" + 0.010*\"base\" + 0.010*\"approach\" + 0.010*\"time\" + 0.008*\"propose\" + 0.008*\"graph\" + 0.008*\"agent\" + 0.008*\"data\" + 0.007*\"query\"\n",
      "Topic: 16 \n",
      "Words: 0.020*\"query\" + 0.014*\"data\" + 0.012*\"base\" + 0.008*\"study\" + 0.008*\"propose\" + 0.008*\"information\" + 0.008*\"measure\" + 0.007*\"privacy\" + 0.007*\"location\" + 0.007*\"evaluation\"\n",
      "Topic: 17 \n",
      "Words: 0.018*\"base\" + 0.014*\"cluster\" + 0.014*\"data\" + 0.011*\"approach\" + 0.010*\"propose\" + 0.010*\"model\" + 0.010*\"cloud\" + 0.008*\"method\" + 0.007*\"time\" + 0.006*\"resource\"\n",
      "Topic: 18 \n",
      "Words: 0.013*\"data\" + 0.012*\"query\" + 0.012*\"base\" + 0.011*\"detection\" + 0.009*\"network\" + 0.009*\"index\" + 0.008*\"approach\" + 0.007*\"algorithm\" + 0.007*\"analysis\" + 0.007*\"cluster\"\n",
      "Topic: 19 \n",
      "Words: 0.035*\"model\" + 0.027*\"network\" + 0.010*\"base\" + 0.010*\"process\" + 0.009*\"energy\" + 0.008*\"data\" + 0.007*\"service\" + 0.007*\"result\" + 0.006*\"propose\" + 0.005*\"different\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Can you distinguish different topics using the words in each topic and their corresponding weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running LDA using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=15, id2word=dictionary, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.004*\"vote\" + 0.004*\"peer\" + 0.004*\"document\" + 0.003*\"attack\" + 0.003*\"network\" + 0.003*\"query\" + 0.003*\"data\" + 0.003*\"security\" + 0.003*\"information\" + 0.003*\"design\"\n",
      "Topic: 1 Word: 0.006*\"health\" + 0.004*\"data\" + 0.003*\"privacy\" + 0.003*\"process\" + 0.003*\"service\" + 0.003*\"model\" + 0.003*\"information\" + 0.003*\"sequence\" + 0.003*\"compression\" + 0.003*\"network\"\n",
      "Topic: 2 Word: 0.003*\"sensor\" + 0.003*\"document\" + 0.003*\"data\" + 0.003*\"score\" + 0.003*\"tree\" + 0.003*\"network\" + 0.003*\"sort\" + 0.003*\"query\" + 0.003*\"sequence\" + 0.003*\"information\"\n",
      "Topic: 3 Word: 0.007*\"cloud\" + 0.004*\"data\" + 0.004*\"service\" + 0.004*\"energy\" + 0.003*\"cluster\" + 0.003*\"model\" + 0.003*\"text\" + 0.003*\"compute\" + 0.003*\"query\" + 0.003*\"network\"\n",
      "Topic: 4 Word: 0.004*\"model\" + 0.004*\"process\" + 0.004*\"data\" + 0.004*\"pattern\" + 0.003*\"document\" + 0.003*\"protein\" + 0.003*\"test\" + 0.003*\"mine\" + 0.003*\"methods\" + 0.003*\"agent\"\n",
      "Topic: 5 Word: 0.007*\"query\" + 0.004*\"data\" + 0.004*\"cloud\" + 0.003*\"cluster\" + 0.003*\"object\" + 0.003*\"network\" + 0.003*\"compute\" + 0.003*\"nearest\" + 0.003*\"neighbor\" + 0.003*\"detection\"\n",
      "Topic: 6 Word: 0.005*\"game\" + 0.003*\"query\" + 0.003*\"social\" + 0.003*\"design\" + 0.003*\"technology\" + 0.003*\"model\" + 0.003*\"data\" + 0.003*\"approach\" + 0.003*\"distance\" + 0.003*\"children\"\n",
      "Topic: 7 Word: 0.004*\"mobile\" + 0.004*\"model\" + 0.004*\"cloud\" + 0.004*\"data\" + 0.003*\"process\" + 0.003*\"compute\" + 0.003*\"users\" + 0.003*\"information\" + 0.003*\"user\" + 0.003*\"learn\"\n",
      "Topic: 8 Word: 0.005*\"model\" + 0.004*\"cloud\" + 0.004*\"cod\" + 0.004*\"fuzzy\" + 0.004*\"energy\" + 0.003*\"data\" + 0.003*\"process\" + 0.003*\"storage\" + 0.003*\"compute\" + 0.003*\"file\"\n",
      "Topic: 9 Word: 0.006*\"cluster\" + 0.004*\"data\" + 0.004*\"model\" + 0.004*\"cloud\" + 0.003*\"image\" + 0.003*\"algorithm\" + 0.003*\"feature\" + 0.003*\"retinal\" + 0.003*\"service\" + 0.003*\"reliability\"\n",
      "Topic: 10 Word: 0.004*\"topic\" + 0.003*\"model\" + 0.003*\"data\" + 0.003*\"approach\" + 0.003*\"network\" + 0.003*\"social\" + 0.003*\"word\" + 0.003*\"flow\" + 0.003*\"semantic\" + 0.003*\"cloud\"\n",
      "Topic: 11 Word: 0.006*\"cloud\" + 0.005*\"game\" + 0.005*\"network\" + 0.004*\"schedule\" + 0.003*\"model\" + 0.003*\"resource\" + 0.003*\"data\" + 0.003*\"social\" + 0.003*\"process\" + 0.003*\"service\"\n",
      "Topic: 12 Word: 0.006*\"model\" + 0.005*\"process\" + 0.005*\"data\" + 0.003*\"cloud\" + 0.003*\"mobile\" + 0.003*\"service\" + 0.003*\"information\" + 0.003*\"systems\" + 0.003*\"task\" + 0.003*\"users\"\n",
      "Topic: 13 Word: 0.006*\"graph\" + 0.005*\"query\" + 0.004*\"service\" + 0.004*\"process\" + 0.004*\"document\" + 0.004*\"digital\" + 0.003*\"cloud\" + 0.003*\"library\" + 0.003*\"grid\" + 0.003*\"data\"\n",
      "Topic: 14 Word: 0.004*\"model\" + 0.004*\"agent\" + 0.003*\"data\" + 0.003*\"user\" + 0.003*\"systems\" + 0.003*\"research\" + 0.003*\"query\" + 0.003*\"time\" + 0.003*\"process\" + 0.003*\"design\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification of the topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation by classifying sample document using LDA Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 1), (6, 1), (21, 1), (42, 1), (48, 2), (62, 1), (63, 1), (64, 1), (72, 6), (73, 1), (74, 1), (86, 1), (90, 5), (93, 2), (94, 5), (96, 2), (99, 1), (104, 1), (110, 1), (129, 1), (166, 1), (167, 1), (168, 1), (169, 1), (170, 1), (171, 3), (172, 1), (173, 1), (174, 1), (175, 1), (176, 2), (177, 1), (178, 1), (179, 2), (180, 1), (181, 1), (182, 1), (183, 1), (184, 1), (185, 1), (186, 2), (187, 1), (188, 3), (189, 1), (190, 1), (191, 2), (192, 1), (193, 1), (194, 1), (195, 1), (196, 1), (197, 2), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1)]\n",
      "Memory efficient ranking:Fast and effective ranking of a collection of documents with respect to a query requires several structures, including a vocabulary, inverted file entries, arrays of term weights and document lengths, a set of partial similarity accumulators, and address tables for inverted file entries and documents. Of all of these structures, the array of document lengths and the set of accumulators are the components accessed most frequently in a ranked query, and it is crucial to acceptable performance that they be held in main memory. Here we describe an approximate ranking process that makes use of a compact array of in-memory, low-precision approximations for the lengths. Combined with another simple rule for reducing the memory required by the partial similarity accumulators, the approximation heuristic allows the ranking of large document collections using less than one byte of memory per document, an eight-fold reduction compared with conventional techniques. Moreover, in our experiments retrieval effectiveness was largely unaffected by the use of these heuristics. © 1994.\n",
      "\n",
      "Score: 0.6493511199951172\t \n",
      "Topic: 0.004*\"mobile\" + 0.004*\"model\" + 0.004*\"cloud\" + 0.004*\"data\" + 0.003*\"process\" + 0.003*\"compute\" + 0.003*\"users\" + 0.003*\"information\" + 0.003*\"user\" + 0.003*\"learn\" + 0.003*\"design\" + 0.003*\"service\" + 0.003*\"grid\" + 0.003*\"social\" + 0.003*\"research\" + 0.002*\"base\" + 0.002*\"technologies\" + 0.002*\"network\" + 0.002*\"technology\" + 0.002*\"study\"\n",
      "\n",
      "Score: 0.31649643182754517\t \n",
      "Topic: 0.004*\"vote\" + 0.004*\"peer\" + 0.004*\"document\" + 0.003*\"attack\" + 0.003*\"network\" + 0.003*\"query\" + 0.003*\"data\" + 0.003*\"security\" + 0.003*\"information\" + 0.003*\"design\" + 0.003*\"test\" + 0.003*\"scheme\" + 0.003*\"file\" + 0.002*\"detection\" + 0.002*\"approach\" + 0.002*\"code\" + 0.002*\"program\" + 0.002*\"model\" + 0.002*\"research\" + 0.002*\"social\"\n",
      "\n",
      "Score: 0.024508066475391388\t \n",
      "Topic: 0.007*\"cloud\" + 0.004*\"data\" + 0.004*\"service\" + 0.004*\"energy\" + 0.003*\"cluster\" + 0.003*\"model\" + 0.003*\"text\" + 0.003*\"compute\" + 0.003*\"query\" + 0.003*\"network\" + 0.003*\"process\" + 0.003*\"applications\" + 0.003*\"approach\" + 0.003*\"sequence\" + 0.003*\"base\" + 0.002*\"center\" + 0.002*\"different\" + 0.002*\"compression\" + 0.002*\"propose\" + 0.002*\"algorithm\"\n"
     ]
    }
   ],
   "source": [
    "i = 4\n",
    "\n",
    "def docText(documents,index):\n",
    "    text = documents[documents['index'] == index].values[0][0]\n",
    "    return text\n",
    "print(bow_corpus[i])\n",
    "print(docText(documents,i))\n",
    "for index, score in sorted(lda_model_tfidf[bow_corpus[i]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 20)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(15, 1), (42, 2), (48, 2), (67, 1), (84, 1), (96, 1), (103, 1), (143, 1), (160, 1), (193, 1), (199, 1), (204, 2), (262, 3), (312, 1), (317, 1), (348, 2), (349, 1), (414, 1), (435, 4), (436, 1), (456, 1), (483, 1), (545, 1), (678, 1), (864, 2), (918, 1), (939, 1), (940, 1), (968, 1), (970, 2), (1081, 1), (1210, 1), (1211, 1), (1212, 1), (1213, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(bow_corpus[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.4900451898574829\t \n",
      "Topic: 0.020*\"queri\" + 0.019*\"model\" + 0.013*\"method\" + 0.010*\"propos\" + 0.010*\"base\" + 0.009*\"network\" + 0.009*\"result\" + 0.008*\"data\" + 0.007*\"user\" + 0.007*\"time\"\n",
      "\n",
      "Score: 0.3876887261867523\t \n",
      "Topic: 0.016*\"applic\" + 0.015*\"resourc\" + 0.011*\"comput\" + 0.011*\"model\" + 0.010*\"cloud\" + 0.009*\"perform\" + 0.009*\"base\" + 0.008*\"process\" + 0.008*\"propos\" + 0.008*\"data\"\n",
      "\n",
      "Score: 0.10735906660556793\t \n",
      "Topic: 0.019*\"cloud\" + 0.017*\"servic\" + 0.010*\"resourc\" + 0.009*\"model\" + 0.009*\"user\" + 0.009*\"research\" + 0.009*\"provid\" + 0.008*\"comput\" + 0.008*\"data\" + 0.008*\"inform\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[100]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test document has the highest probability to be part of the topic on the top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation by classifying sample document using LDA TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.42658671736717224\t \n",
      "Topic: 0.006*\"cloud\" + 0.005*\"process\" + 0.005*\"data\" + 0.004*\"model\" + 0.004*\"document\"\n",
      "\n",
      "Score: 0.3463570177555084\t \n",
      "Topic: 0.004*\"data\" + 0.003*\"model\" + 0.003*\"network\" + 0.003*\"query\" + 0.003*\"process\"\n",
      "\n",
      "Score: 0.1227799579501152\t \n",
      "Topic: 0.006*\"cod\" + 0.004*\"cloud\" + 0.004*\"function\" + 0.004*\"offload\" + 0.004*\"outlier\"\n",
      "\n",
      "Score: 0.05606284365057945\t \n",
      "Topic: 0.010*\"cloud\" + 0.005*\"social\" + 0.004*\"data\" + 0.004*\"service\" + 0.004*\"resource\"\n",
      "\n",
      "Score: 0.039035771042108536\t \n",
      "Topic: 0.005*\"cluster\" + 0.004*\"cloud\" + 0.004*\"algorithm\" + 0.004*\"service\" + 0.004*\"performance\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[3981]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test document has the highest probability to be part of the topic on the top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model on unseen document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.3733212351799011\t Topic: 0.006*\"mobile\" + 0.005*\"data\" + 0.004*\"social\" + 0.004*\"privacy\" + 0.003*\"research\"\n",
      "Score: 0.26307183504104614\t Topic: 0.006*\"cloud\" + 0.005*\"process\" + 0.005*\"data\" + 0.004*\"model\" + 0.004*\"document\"\n",
      "Score: 0.16387544572353363\t Topic: 0.006*\"game\" + 0.005*\"data\" + 0.004*\"design\" + 0.003*\"network\" + 0.003*\"mutations\"\n",
      "Score: 0.11993960291147232\t Topic: 0.005*\"cluster\" + 0.004*\"model\" + 0.004*\"data\" + 0.004*\"program\" + 0.003*\"network\"\n",
      "Score: 0.06462649255990982\t Topic: 0.004*\"data\" + 0.003*\"model\" + 0.003*\"network\" + 0.003*\"query\" + 0.003*\"process\"\n"
     ]
    }
   ],
   "source": [
    "# unseen_document = \"machine learning\"\n",
    "unseen_document = \"The use of randomness in the designing of the digital devices has been discussed. Qualities of randomness such as unpredictability, indeterminacy and unexpectedness have been used as a creative resource to generate innovative , output. Randomness is a creative tool to inspire and generate innovative outputs that is a means to an end. The growth of digital interactivity has been accompanied by a increasing amount of interactive that express certain qualities of randomness during use. An emergent approach toward randomness is to allow users to interact directly with the randomness. Shuffle listening, which is an alternative listening mode offered by digital music players, is a more sophisticated approach, whereby application of randomness has publicly captured by imagination of many people. Considerations, in determining where a random feature can be used, should include the types of content, the domain and contexts where these digital devices are used\"\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "\n",
    "for index, score in sorted(lda_model_tfidf[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model_tfidf.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
